{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ideal amount of features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoukzwinkels/TM10007/blob/master/Ideal_amount_of_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYZ8F3PTxb-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2287aa6a-0395-42d1-aaff-9b2509911556"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection    import StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.model_selection    import StratifiedShuffleSplit, RandomizedSearchCV\n",
        "from sklearn.feature_selection  import VarianceThreshold, RFECV, SelectKBest, f_classif\n",
        "from sklearn.metrics            import accuracy_score\n",
        "from sklearn.metrics            import roc_auc_score\n",
        "from sklearn.preprocessing      import RobustScaler\n",
        "from sklearn.neighbors          import KNeighborsClassifier\n",
        "from sklearn.svm                import SVC\n",
        "from sklearn.decomposition      import PCA\n",
        "\n",
        "from plotly.express             import scatter_3d, bar\n",
        "from sklearn.ensemble           import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVEvAdBkxc6P"
      },
      "source": [
        "def def_data():\n",
        "  '''\n",
        "  Load the data\n",
        "  \n",
        "  :return features:     dataframe containing the features\n",
        "  :return labels:       dataframe containing the labels\n",
        "  '''\n",
        "\n",
        "  from hn.load_data import load_data\n",
        "  data = load_data()\n",
        "\n",
        "  features = data.drop(columns=['label'])\n",
        "  labels = pd.DataFrame(data['label'])\n",
        "\n",
        "  return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASF_Wngfxe2R"
      },
      "source": [
        "def remove_outliers(X_train):\n",
        "  '''\n",
        "  Identify the outliers and replace them with the minimum or maximum value of the corresponding feature.\n",
        "\n",
        "  :param X_train:      dataframe containing the features of the traindata\n",
        "  :return X_train:     dataframe containing the features of the traindata with the outliers corrected\n",
        "  '''\n",
        "\n",
        "  X_train = X_train.copy()\n",
        "  \n",
        "  # calculate interquartile range\n",
        "  q25, q75 = np.percentile(X_train, 25,axis=0), np.percentile(X_train, 75,axis=0)\n",
        "  iqr = q75 - q25\n",
        "\n",
        "  # calculate the outlier cutoff\n",
        "  cut_off = iqr * 1.5\n",
        "  lower, upper = q25 - cut_off, q75 + cut_off\n",
        "\n",
        "  # Identify outliers\n",
        "  outliers = (X_train < lower) | (X_train > upper)\n",
        "\n",
        "  # Replace outliers with min or max value of non-outliers of corresponding feature\n",
        "  feature_nan = X_train[:].copy()\n",
        "  feature_nan[outliers] = np.nan\n",
        "\n",
        "  feature_names = list(X_train.columns)\n",
        "  for col in feature_names:\n",
        "    outliers_col = outliers[col]\n",
        "    for val in X_train.loc[outliers_col,col]:\n",
        "      if val > np.nanmax(feature_nan[col]):\n",
        "        X_train[col] = X_train[col].replace(to_replace = val, value = np.nanmax(feature_nan[col]))\n",
        "      elif val < np.nanmin(feature_nan[col]):\n",
        "        X_train[col] = X_train[col].replace(to_replace = val, value = np.nanmin(feature_nan[col]))\n",
        "  return (X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4FXvqoDxlYC"
      },
      "source": [
        "def remove_zero_variance(X_train, X_test):\n",
        "  '''\n",
        "  Remove the features with zero variance. The data is fitted on the X_train and applied to X_train and X_test.\n",
        "\n",
        "  :param X_train:     dataframe containing the features of the traindata           \n",
        "  :param X_test:      dataframe containing the features of the testdata         \n",
        "  :return X_train:    dataframe containing the features of the traindata with the features with zero variance removed\n",
        "  :return X_test:     dataframe containing the features of the testdata with the features with zero variance removed\n",
        "  '''\n",
        "\n",
        "  # Removing the features that have the same value in all samples\n",
        "  m = VarianceThreshold(threshold=0.0)\n",
        "  m.fit(X_train)\n",
        "  names_chosen_features = m.get_support(indices = True)\n",
        "  X_train = X_train.iloc[:,names_chosen_features]\n",
        "  X_test = X_test.iloc[:,names_chosen_features]\n",
        "\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9z_mTA6zhT4"
      },
      "source": [
        "def scaling(X_train, X_test):\n",
        "  '''\n",
        "  To scale the test and train data.\n",
        "\n",
        "  :param X_train:         dataframe containing the features of the traindata           \n",
        "  :param X_test:          dataframe containing the features of the testdata               \n",
        "  :return X_train:        dataframe containing the scaled features of the traindata\n",
        "  :return X_test:         dataframe containing the scaled features of the testdata\n",
        "  '''\n",
        "  \n",
        "  # Scale the data\n",
        "  scaler = RobustScaler()\n",
        "  scaler.fit(X_train)\n",
        "  X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
        "  X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aN_iMS4xp4S"
      },
      "source": [
        "def ideal_features(y_train, X_train, repeat = 5):\n",
        "  '''\n",
        "  Creates a \n",
        "\n",
        "  :param X_train:         dataframe containing features of the the traindata           \n",
        "  :param X_test:          dataframe containing features of the the testdata\n",
        "  :param repeat:          number of repeats\n",
        "  '''\n",
        "  \n",
        "  # Calculate the cross-validation score per amount of selected features\n",
        "  scores = []\n",
        "  times = 0\n",
        "  Y=np.ravel(y_train)\n",
        "\n",
        "  while not (times == repeat):\n",
        "    times += 1\n",
        "    rfecv = RFECV(\n",
        "        estimator=RandomForestClassifier(n_estimators=10), step=1,\n",
        "        cv=RepeatedStratifiedKFold(n_splits=10),\n",
        "        scoring='roc_auc')\n",
        "    rfecv.fit(X_train, Y)\n",
        "    scores.append(rfecv.grid_scores_)\n",
        "\n",
        "  mean_scores = np.mean(scores, axis=0)\n",
        "\n",
        "  # Plot results\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Number of features selected\")\n",
        "  plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "  plt.plot(range(1, len(mean_scores) + 1), mean_scores)\n",
        "  plt.show()\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ieukt3viMS"
      },
      "source": [
        "# Execute definitions\n",
        "# This has been run a few times to determine the ideal amount of features\n",
        "features, labels = def_data()\n",
        "\n",
        "loops = 0\n",
        "sss = StratifiedShuffleSplit(n_splits=10)\n",
        "for train_index, test_index in sss.split(features, labels):\n",
        "  if loops == 1:\n",
        "    break\n",
        "  else:\n",
        "    loops += 1\n",
        "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
        "    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
        "\n",
        "    y_train = np.ravel(y_train)\n",
        "    X_train = remove_outliers(X_train)\n",
        "    X_train, X_test = scaling(X_train, X_test)\n",
        "    X_train, X_test = remove_zero_variance(X_train, X_test)\n",
        "    ideal_features(y_train, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}